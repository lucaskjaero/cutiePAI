{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from import_data import load_data\n",
    "x_train, y_train, x_test, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/1\n",
      "28709/28709 [==============================] - 502s - loss: 0.3633 - acc: 0.8620 - val_loss: 0.3216 - val_acc: 0.8743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, fbeta_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.keras as k\n",
    "from tensorflow.contrib.keras.python.keras.models import Sequential\n",
    "from tensorflow.contrib.keras.python.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.contrib.keras.python.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3),\n",
    "             activation='relu',\n",
    "             input_shape=(48, 48, 1)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "      batch_size=128,\n",
    "      epochs=1,\n",
    "      verbose=1,\n",
    "      validation_data=(x_test, y_test))\n",
    "\n",
    "from os.path import expanduser\n",
    "model.save(expanduser(\"softmodel0to1.hd5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't handle mix of multilabel-indicator and continuous-multioutput",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aab1fbe33a51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~/emotion/model.hd5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F-Beta: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Documents/EmoSanDiego/emo-sandiego/train.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, x_test, y_test)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mindex_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mfinal_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mfbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfbeta_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/hackathon/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/hackathon/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         raise ValueError(\"Can't handle mix of {0} and {1}\"\n\u001b[0;32m---> 82\u001b[0;31m                          \"\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't handle mix of multilabel-indicator and continuous-multioutput"
     ]
    }
   ],
   "source": [
    "from os.path import expanduser\n",
    "from tensorflow.contrib.keras.python.keras.models import load_model\n",
    "from import_data import process_output\n",
    "from train import test_model\n",
    "\n",
    "model = load_model(expanduser(\"~/emotion/model.hd5\"))\n",
    "accuracy, fbeta = test_model(model, x_test, y_test)\n",
    "print(\"Accuracy: %s\" % accuracy)\n",
    "print(\"F-Beta: %s\" % fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 6, 3, 5, 6, 4, 4, 4, 0, 4, 5, 3, 6, 6, 4, 6, 5, 5, 5, 5, 6, 4, 6, 6, 6, 4, 5, 6, 6, 3, 6, 4, 4, 6, 0, 6, 5, 2, 3, 6, 0, 6, 4, 4, 6, 6, 3, 6, 6, 6, 4, 5, 6, 3, 0, 6, 5, 6, 6, 4, 4, 6, 4, 6, 4, 0, 3, 6, 6, 4, 4, 3, 6, 6, 6, 6, 6, 5, 6, 4, 6, 6, 6, 4, 6, 6, 2, 0, 6, 5, 6, 4, 0, 6, 4, 6, 4, 5, 4, 6, 6, 6, 6, 6, 3, 6, 6, 6, 5, 6, 6, 0, 4, 5, 3, 6, 6, 4, 6, 6, 6, 3, 5, 6, 4, 4, 4, 6, 6, 6, 6, 6, 4, 4, 6, 6, 4, 3, 4, 0, 5, 0, 6, 4, 0, 6, 5, 3, 6, 6, 6, 6, 6, 6, 4, 4, 6, 6, 6, 3, 4, 4, 3, 5, 6, 6, 6, 6, 3, 6, 5, 5, 6, 5, 6, 5, 4, 6, 5, 6, 4, 6, 6, 6, 0, 6, 5, 5, 6, 6, 3, 6, 6, 4, 3, 6, 5, 6, 6, 4, 6, 0, 4, 2, 6, 6, 4, 6, 4, 4, 6, 6, 5, 4, 4, 6, 4, 4, 4, 4, 3, 5, 5, 5, 4, 4, 5, 6, 6, 4, 3, 6, 6, 6, 6, 6, 0, 4, 6, 6, 4, 4, 0, 4, 6, 4, 4, 4, 3, 6, 6, 6, 4, 4, 4, 6, 6, 3, 3, 6, 6, 0, 4, 6, 4, 4, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 6, 0, 6, 0, 4, 3, 6, 6, 6, 6, 5, 4, 4, 4, 4, 6, 6, 4, 4, 5, 6, 4, 6, 6, 0, 5, 0, 4, 4, 4, 4, 6, 4, 6, 6, 4, 6, 6, 6, 6, 6, 4, 6, 6, 6, 6, 0, 6, 0, 4, 6, 5, 6, 3, 6, 6, 4, 6, 6, 6, 5, 6, 4, 4, 6, 6, 6, 0, 5, 3, 4, 6, 3, 3, 6, 0, 6, 6, 4, 4, 4, 4, 6, 5, 4, 3, 6, 6, 5, 5, 6, 4, 6, 4, 3, 4, 6, 6, 4, 6, 6, 4, 0, 4, 4, 6, 4, 6, 3, 4, 6, 6, 6, 3, 6, 6, 4, 6, 3, 6, 0, 5, 0, 5, 3, 6, 6, 6, 6, 6, 5, 4, 4, 4, 6, 4, 4, 6, 6, 6, 0, 6, 6, 4, 4, 6, 3, 6, 3, 4, 6, 6, 6, 6, 4, 6, 0, 6, 4, 5, 4, 0, 3, 6, 6, 0, 6, 6, 6, 4, 6, 4, 3, 4, 6, 0, 6, 6, 6, 6, 4, 6, 5, 6, 3, 6, 4, 6, 4, 6, 0, 6, 6, 6, 6, 6, 5, 4, 6, 6, 6, 4, 3, 6, 6, 5, 4, 6, 6, 6, 5, 6, 6, 3, 5, 4, 4, 6, 6, 2, 5, 3, 3, 6, 6, 5, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 4, 6, 6, 3, 6, 2, 6, 0, 6, 6, 6, 0, 6, 3, 4, 6, 6, 3, 5, 3, 6, 4, 4, 6, 4, 6, 4, 6, 4, 6, 4, 5, 6, 3, 6, 3, 6, 6, 6, 4, 4, 6, 6, 6, 0, 0, 4, 6, 6, 4, 0, 3, 5, 6, 6, 6, 3, 6, 6, 4, 0, 0, 6, 4, 4, 6, 6, 4, 4, 3, 6, 5, 6, 6, 6, 5, 4, 6, 4, 3, 6, 5, 3, 6, 6, 6, 6, 6, 6, 6, 4, 6, 6, 4, 3, 6, 6, 6, 2, 3, 6, 3, 0, 4, 4, 0, 4, 6, 6, 6, 5, 6, 6, 6, 3, 6, 6, 4, 5, 4, 4, 4, 6, 6, 6, 4, 6, 5, 6, 6, 6, 3, 4, 3, 3, 6, 6, 3, 4, 3, 6, 4, 3, 4, 6, 4, 3, 4, 4, 6, 6, 4, 4, 6, 6, 6, 6, 6, 3, 6, 4, 4, 6, 5, 6, 6, 6, 0, 6, 6, 6, 6, 6, 5, 4, 6, 6, 4, 3, 4, 6, 5, 6, 6, 3, 6, 6, 6, 3, 4, 6, 4, 6, 6, 3, 0, 6, 3, 6, 6, 6, 6, 6, 4, 6, 6, 6, 4, 5, 6, 4, 3, 6, 4, 6, 4, 4, 6, 6, 3, 4, 4, 2, 4, 6, 0, 6, 6, 6, 6, 6, 5, 4, 6, 0, 3, 6, 4, 6, 4, 6, 4, 5, 4, 5, 6, 4, 4, 4, 4, 6, 6, 4, 3, 6, 6, 6, 4, 6, 6, 6, 4, 0, 6, 6, 3, 0, 5, 5, 3, 4, 6, 6, 0, 5, 6, 4, 5, 4, 3, 4, 6, 6, 3, 6, 4, 4, 6, 6, 6, 6, 6, 4, 6, 6, 4, 4, 6, 6, 6, 5, 0, 4, 6, 4, 5, 6, 6, 6, 6, 6, 6, 4, 6, 3, 4, 3, 6, 0, 0, 3, 6, 6, 6, 6, 4, 5, 6, 0, 4, 6, 3, 4, 6, 5, 3, 4, 6, 4, 5, 3, 6, 6, 5, 6, 6, 6, 0, 5, 6, 6, 3, 3, 3, 6, 3, 3, 6, 6, 6, 6, 6, 6, 4, 3, 6, 4, 6, 4, 6, 6, 4, 6, 6, 6, 3, 5, 5, 0, 6, 3, 3, 0, 6, 3, 3, 6, 6, 6, 6, 6, 6, 4, 4, 3, 4, 6, 4, 6, 3, 6, 6, 4, 6, 4, 6, 5, 4, 4, 6, 6, 6, 4, 5, 6, 6, 4, 6, 3, 6, 4, 6, 6, 3, 6, 4, 2, 4, 6, 6, 6, 5, 5, 3, 4, 0, 6, 3, 6, 6, 3, 4, 6, 4, 3, 4, 6, 4, 6, 6, 4, 6, 6, 6, 6, 3, 0, 6, 6, 4, 6, 3, 6, 2, 6, 3, 6, 4, 6, 4, 3, 3, 6, 6, 6, 6, 6, 5, 4, 4, 6, 4, 3, 5, 4, 6, 6, 6, 4, 6, 3, 4, 0, 6, 4, 6, 4, 6, 6, 6, 6, 6, 6, 5, 6, 4, 3, 6, 0, 6, 3, 5, 6, 5, 6, 5, 6, 6, 4, 6, 6, 4, 5, 6, 4, 6, 6, 4, 6, 3, 6, 0, 6, 6, 6, 6, 6, 4, 0, 0, 4, 0, 4, 3, 6, 4, 5, 3, 6, 3, 4, 6, 5, 3, 6, 6, 6, 6, 4, 4, 6, 6, 6, 6, 6, 6, 0, 5, 4, 4, 5, 4, 6, 4, 0, 3, 6, 4, 4, 4, 6, 2, 6, 6, 6, 5, 6, 5, 5, 6, 5, 6, 6, 6, 6, 4, 4, 0, 5, 6, 4, 6, 6, 4, 6, 6, 6, 4, 4, 4, 6, 6, 6, 6, 5, 6, 6, 5, 5, 6, 0, 6, 4, 6, 6, 4, 5, 6, 6, 4, 0, 6, 6, 4, 6, 6, 4, 6, 6, 6, 6, 6, 4, 6, 4, 6, 0, 6, 5, 6, 3, 6, 6, 5, 4, 4, 3, 6, 6, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 5, 5, 4, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 5, 6, 5, 6, 3, 0, 3, 6, 6, 3, 6, 6, 4, 4, 6, 4, 6, 4, 6, 4, 4, 6, 5, 3, 6, 6, 6, 3, 6, 0, 4, 6, 6, 3, 6, 6, 6, 3, 6, 0, 3, 6, 0, 4, 4, 6, 5, 5, 6, 5, 4, 6, 3, 4, 6, 6, 4, 4, 6, 6, 6, 0, 6, 6, 6, 4, 6, 6, 6, 6, 3, 6, 3, 6, 3, 4, 6, 6, 5, 0, 6, 6, 5, 4, 6, 4, 6, 2, 6, 6, 6, 4, 6, 5, 5, 6, 5, 4, 6, 4, 4, 6, 6, 6, 2, 4, 6, 6, 4, 6, 3, 6, 4, 6, 6, 5, 6, 5, 6, 4, 4, 6, 6, 6, 4, 4, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 4, 4, 6, 4, 6, 4, 4, 5, 4, 0, 6, 6, 5, 6, 3, 6, 0, 3, 0, 3, 6, 3, 5, 4, 6, 3, 4, 6, 6, 0, 6, 4, 6, 5, 6, 6, 6, 0, 6, 4, 3, 4, 0, 3, 6, 6, 6, 6, 3, 6, 6, 6, 6, 0, 3, 4, 4, 3, 0, 4, 6, 4, 3, 6, 6, 6, 0, 4, 6, 6, 6, 6, 6, 0, 6, 4, 4, 6, 6, 6, 3, 3, 4, 6, 6, 4, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 2, 3, 6, 4, 4, 2, 6, 6, 6, 6, 4, 5, 4, 6, 6, 6, 6, 6, 4, 6, 6, 5, 6, 6, 4, 0, 4, 4, 4, 6, 0, 6, 4, 6, 0, 4, 3, 4, 4, 4, 6, 6, 4, 6, 4, 6, 6, 6, 6, 6, 6, 6, 4, 4, 6, 4, 6, 6, 0, 6, 6, 3, 4, 5, 3, 6, 6, 5, 4, 6, 6, 6, 5, 4, 6, 6, 4, 6, 6, 6, 6, 6, 4, 6, 4, 6, 4, 5, 4, 6, 5, 6, 6, 6, 6, 6, 0, 5, 3, 5, 4, 6, 6, 4, 6, 3, 4, 4, 3, 6, 5, 6, 4, 6, 5, 6, 4, 4, 6, 4, 6, 6, 6, 6, 6, 5, 3, 6, 5, 4, 3, 6, 6, 4, 6, 6, 3, 6, 6, 6, 3, 6, 6, 4, 4, 3, 4, 4, 5, 6, 6, 4, 6, 6, 3, 6, 6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 4, 6, 6, 6, 5, 3, 4, 4, 4, 6, 4, 6, 6, 6, 5, 4, 6, 6, 4, 5, 0, 6, 4, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 6, 6, 3, 2, 4, 4, 4, 6, 4, 3, 6, 6, 3, 6, 5, 6, 4, 4, 6, 5, 3, 3, 6, 6, 6, 4, 6, 6, 6, 3, 5, 6, 6, 6, 6, 6, 2, 6, 4, 5, 3, 6, 3, 4, 4, 3, 4, 4, 5, 3, 6, 6, 6, 0, 4, 3, 5, 6, 0, 0, 4, 4, 4, 6, 6, 4, 4, 2, 6, 4, 5, 6, 6, 3, 5, 6, 6, 3, 4, 4, 4, 6, 5, 6, 6, 6, 4, 6, 6, 6, 6, 3, 5, 2, 4, 6, 6, 5, 4, 3, 3, 3, 5, 6, 6, 6, 6, 6, 3, 6, 5, 6, 5, 4, 4, 3, 0, 4, 6, 6, 3, 6, 6, 3, 4, 6, 6, 6, 4, 4, 6, 2, 6, 4, 4, 6, 6, 4, 6, 3, 0, 3, 3, 4, 0, 6, 6, 4, 6, 4, 0, 6, 3, 6, 6, 6, 3, 6, 6, 2, 4, 6, 5, 4, 4, 6, 4, 3, 6, 6, 5, 6, 6, 5, 0, 6, 6, 4, 3, 5, 6, 6, 6, 6, 4, 4, 6, 3, 4, 4, 4, 0, 5, 0, 6, 6, 4, 6, 5, 6, 6, 0, 3, 6, 5, 4, 5, 6, 6, 6, 4, 6, 4, 6, 0, 6, 6, 4, 5, 6, 5, 6, 4, 4, 0, 4, 6, 5, 4, 4, 6, 6, 6, 6, 6, 3, 0, 6, 5, 4, 4, 4, 0, 5, 6, 5, 4, 6, 4, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 2, 6, 0, 3, 2, 6, 6, 4, 6, 6, 3, 6, 6, 4, 4, 3, 6, 6, 6, 4, 0, 6, 6, 4, 6, 3, 6, 4, 6, 6, 6, 5, 6, 6, 6, 3, 5, 6, 5, 5, 5, 4, 6, 6, 6, 4, 6, 4, 2, 4, 4, 6, 3, 4, 3, 4, 6, 0, 6, 6, 6, 6, 6, 6, 4, 4, 6, 4, 6, 5, 6, 6, 5, 4, 5, 6, 6, 3, 6, 6, 3, 6, 4, 6, 5, 6, 6, 6, 6, 2, 4, 6, 6, 3, 4, 6, 4, 6, 6, 4, 6, 4, 6, 4, 6, 6, 5, 6, 6, 6, 6, 6, 5, 2, 3, 6, 6, 0, 6, 5, 6, 0, 6, 6, 3, 3, 5, 4, 6, 6, 4, 4, 5, 6, 6, 6, 4, 5, 4, 5, 4, 6, 6, 6, 3, 6, 4, 3, 4, 4, 6, 6, 6, 6, 6, 5, 4, 6, 5, 6, 3, 6, 0, 6, 6, 6, 6, 4, 6, 6, 4, 4, 6, 6, 6, 6, 6, 5, 6, 3, 6, 6, 5, 3, 6, 6, 6, 6, 6, 4, 3, 3, 5, 4, 6, 3, 4, 6, 6, 6, 0, 4, 6, 6, 6, 6, 3, 4, 5, 6, 6, 6, 4, 6, 0, 5, 3, 6, 6, 4, 6, 6, 4, 4, 6, 6, 6, 6, 6, 6, 3, 0, 6, 4, 6, 6, 4, 4, 5, 6, 3, 4, 4, 6, 3, 6, 3, 6, 6, 6, 3, 5, 6, 6, 6, 6, 6, 4, 4, 6, 6, 4, 6, 6, 2, 3, 6, 3, 3, 4, 5, 6, 4, 6, 6, 6, 4, 4, 6, 4, 4, 4, 4, 4, 5, 6, 6, 4, 6, 6, 6, 4, 5, 4, 6, 6, 6, 4, 6, 6, 4, 6, 6, 3, 4, 6, 3, 6, 2, 6, 6, 0, 0, 6, 2, 6, 6, 4, 3, 6, 6, 5, 3, 4, 6, 6, 4, 6, 6, 6, 5, 5, 6, 0, 6, 5, 6, 6, 3, 4, 4, 4, 6, 4, 2, 5, 4, 6, 6, 4, 6, 6, 6, 6, 4, 6, 5, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 0, 6, 6, 3, 6, 6, 5, 6, 5, 6, 0, 3, 0, 6, 6, 6, 0, 6, 0, 6, 5, 5, 5, 6, 6, 6, 4, 4, 6, 6, 3, 3, 2, 6, 6, 3, 6, 6, 4, 6, 6, 0, 5, 6, 6, 6, 0, 4, 4, 6, 4, 0, 6, 4, 5, 6, 6, 4, 0, 4, 4, 6, 0, 0, 4, 2, 6, 6, 6, 4, 4, 6, 6, 6, 6, 4, 6, 6, 5, 6, 4, 3, 6, 4, 3, 6, 5, 6, 6, 6, 0, 4, 6, 6, 6, 5, 6, 6, 4, 6, 5, 6, 6, 6, 6, 5, 6, 3, 4, 4, 6, 6, 6, 6, 5, 4, 6, 3, 6, 5, 3, 6, 4, 6, 4, 4, 4, 6, 6, 5, 6, 5, 6, 6, 5, 4, 6, 5, 6, 6, 6, 2, 6, 4, 6, 4, 6, 6, 2, 6, 5, 6, 6, 5, 6, 3, 5, 3, 6, 6, 4, 4, 5, 4, 6, 6, 6, 3, 3, 6, 6, 6, 6, 6, 5, 4, 6, 4, 6, 3, 0, 0, 6, 6, 6, 6, 6, 6, 6, 0, 6, 3, 3, 4, 6, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 4, 4, 6, 6, 6, 6, 6, 5, 6, 4, 4, 4, 4, 4, 3, 0, 6, 4, 6, 0, 6, 6, 6, 6, 6, 6, 6, 5, 4, 6, 6, 0, 6, 6, 4, 5, 6, 4, 5, 4, 3, 6, 4, 4, 4, 4, 6, 4, 6, 4, 3, 3, 0, 6, 4, 5, 6, 6, 5, 6, 6, 6, 4, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 4, 5, 6, 4, 6, 4, 4, 6, 6, 6, 6, 6, 6, 6, 4, 3, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 4, 6, 6, 3, 5, 3, 3, 5, 4, 6, 0, 6, 0, 6, 6, 6, 6, 6, 5, 4, 4, 5, 6, 6, 6, 4, 4, 6, 6, 6, 6, 5, 4, 4, 4, 3, 5, 6, 6, 6, 6, 4, 5, 6, 4, 6, 6, 6, 6, 6, 0, 6, 5, 6, 4, 4, 6, 5, 5, 6, 5, 0, 3, 6, 3, 4, 6, 3, 4, 5, 6, 0, 6, 5, 6, 6, 6, 4, 3, 6, 2, 6, 3, 0, 4, 6, 6, 6, 4, 5, 6, 6, 6, 6, 6, 5, 4, 5, 6, 5, 6, 6, 6, 6, 0, 4, 6, 5, 4, 6, 6, 6, 6, 3, 5, 6, 6, 6, 0, 6, 6, 4, 0, 6, 6, 5, 5, 6, 6, 6, 6, 6, 4, 4, 4, 5, 4, 6, 6, 6, 6, 0, 2, 6, 3, 6, 3, 5, 3, 6, 6, 6, 4, 0, 6, 6, 4, 3, 0, 4, 4, 0, 5, 4, 6, 4, 6, 4, 6, 4, 6, 0, 6, 5, 0, 6, 6, 4, 6, 6, 3, 4, 3, 6, 4, 6, 3, 6, 6, 6, 6, 6, 4, 2, 3, 6, 6, 6, 4, 6, 5, 6, 3, 6, 6, 6, 6, 6, 5, 5, 6, 4, 4, 6, 4, 6, 3, 3, 6, 6, 4, 6, 6, 4, 6, 6, 6, 6, 3, 4, 3, 6, 5, 4, 6, 4, 6, 6, 3, 6, 3, 4, 6, 6, 4, 6, 6, 4, 4, 4, 6, 6, 3, 6, 6, 6, 4, 6, 0, 0, 4, 4, 6, 5, 5, 6, 3, 5, 6, 6, 6, 4, 6, 6, 4, 6, 3, 6, 4, 5, 6, 6, 6, 3, 6, 6, 4, 6, 5, 6, 5, 4, 5, 3, 3, 5, 6, 4, 4, 6, 4, 2, 4, 5, 6, 4, 6, 6, 4, 6, 4, 4, 3, 6, 5, 6, 3, 6, 4, 6, 5, 6, 6, 3, 6, 5, 3, 6, 3, 6, 4, 4, 6, 6, 6, 4, 6, 4, 4, 6, 6, 3, 6, 6, 0, 6, 6, 4, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 3, 5, 5, 6, 5, 0, 6, 5, 6, 6, 6, 6, 4, 6, 4, 4, 4, 4, 4, 6, 6, 6, 3, 4, 6, 3, 3, 6, 5, 5, 3, 5, 6, 5, 6, 6, 6, 3, 6, 4, 6, 6, 6, 5, 6, 4, 3, 6, 4, 6, 6, 2, 6, 4, 6, 3, 6, 4, 6, 6, 6, 6, 0, 6, 6, 6, 0, 0, 4, 6, 6, 6, 5, 5, 6, 6, 0, 6, 6, 4, 6, 0, 0, 4, 3, 3, 4, 3, 4, 0, 4, 3, 5, 4, 4, 6, 6, 6, 3, 4, 6, 4, 6, 4, 5, 4, 4, 4, 0, 6, 5, 6, 6, 3, 6, 6, 6, 2, 4, 3, 6, 6, 6, 3, 6, 3, 6, 6, 6, 6, 6, 3, 4, 6, 4, 6, 6, 6, 6, 6, 6, 4, 5, 5, 3, 6, 6, 6, 4, 6, 6, 6, 4, 6, 6, 6, 4, 3, 5, 3, 6, 6, 0, 6, 4, 6, 6, 6, 5, 2, 4, 6, 6, 6, 4, 6, 4, 4, 3, 6, 0, 3, 5, 3, 6, 6, 6, 6, 6, 5, 6, 6, 5, 4, 0, 6, 5, 6, 6, 6, 5, 6, 6, 4, 4, 6, 4, 6, 6, 6, 0, 0, 4, 6, 6, 0, 5, 4, 6, 6, 5, 4, 6, 6, 6, 4, 5, 6, 6, 6, 5, 6, 6, 6, 6, 6, 3, 6, 3, 6, 6, 4, 6, 6, 5, 4, 4, 4, 4, 6, 4, 6, 3, 5, 6, 6, 6, 0, 3, 6, 6, 4, 6, 3, 4, 6, 5, 4, 5, 3, 6, 6, 3, 6, 3, 6, 6, 6, 6, 6, 6, 6, 4, 6, 6, 4, 6, 0, 4, 6, 6, 6, 4, 6, 6, 5, 6, 0, 5, 6, 6, 6, 6, 0, 4, 5, 4, 5, 6, 0, 6, 6, 6, 4, 5, 4, 6, 5, 4, 6, 4, 6, 5, 5, 0, 6, 6, 0, 6, 6, 3, 6, 6, 6, 6, 2, 6, 3, 6, 6, 4, 5, 4, 4, 3, 0, 4, 6, 0, 6, 6, 0, 4, 6, 4, 6, 6, 5, 6, 5, 6, 6, 0, 6, 3, 6, 0, 4, 3, 6, 4, 6, 4, 0, 6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 3, 4, 6, 5, 4, 6, 6, 6, 6, 4, 6, 6, 4, 6, 6, 6, 4, 6, 4, 0, 6, 6, 3, 6, 6, 6, 5, 4, 6, 6, 6, 3, 6, 6, 4, 6, 4, 6, 4, 4, 6, 6, 4, 6, 6, 6, 0, 6, 3, 4, 6, 6, 5, 5, 6, 5, 6, 6, 3, 6, 4, 4, 4, 6, 2, 4, 6, 3, 5, 6, 6, 6, 6, 3, 6, 4, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 4, 3, 4, 4, 3, 4, 6, 0, 5, 0, 6, 6, 4, 3, 6, 4, 6, 6, 6, 6, 5, 6, 4, 4, 5, 5, 6, 2, 4, 6, 5, 0, 5, 6, 6, 6, 6, 5, 3, 3, 6, 4, 3, 5, 3, 6, 2, 3, 4, 3, 6, 6, 6, 6, 4, 6, 5, 6, 2, 6, 5, 6, 4, 6, 6, 6, 0, 4, 6, 4, 5, 6, 0, 0, 3, 4, 6, 4, 4, 4, 6, 3, 6, 6, 3, 4, 5, 6, 3, 6, 6, 6, 6, 6, 6, 5, 3, 5, 5, 6, 6, 6, 6, 6, 4, 5, 5, 6, 4, 6, 4, 6, 6, 6, 5, 4, 5, 6, 3, 6, 4, 2, 6, 3, 3, 4, 0, 5, 5, 3, 3, 6, 6, 4, 6, 6, 6, 6, 6, 6, 6, 0, 6, 5, 6, 4, 6, 6, 4, 4, 0, 6, 6, 5, 6, 6, 6, 4, 4, 0, 6, 4, 6, 4, 6, 4, 6]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't handle mix of multilabel-indicator and multiclass",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0ab250fe23db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfbeta_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/hackathon/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/hackathon/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         raise ValueError(\"Can't handle mix of {0} and {1}\"\n\u001b[0;32m---> 82\u001b[0;31m                          \"\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't handle mix of multilabel-indicator and multiclass"
     ]
    }
   ],
   "source": [
    "predictions = make_prediction(predictions)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from import_data import process_output\n",
    "predictions = process_output(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.311228754528\n",
      "0.311228754528\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %s\" % accuracy_score(y_test, predictions))\n",
    "print(fbeta_score(y_test, np.array(predictions) > 0.2, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "test_model() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-5c939d1c6ad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model = load_data(expanduser(\"~/emotion/model.h5\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F-Beta: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: test_model() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from train import test_model\n",
    "#model = load_data(expanduser(\"~/emotion/model.h5\"))\n",
    "\n",
    "accuracy, fbeta = test_model(model, x_test, y_test)\n",
    "print(\"Accuracy: %s\" % accuracy)\n",
    "print(\"F-Beta: %s\" % fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, x_test, y_test):\n",
    "    predictions = model.predict(x_test, batch_size=128)\n",
    "    index_predictions = []\n",
    "    for row in predictions:\n",
    "        max_index = 0\n",
    "        max_value = row[0]\n",
    "        for index, value in enumerate(row):\n",
    "            if value > max_value:\n",
    "                max_index = index\n",
    "        index_predictions.append(max_index)\n",
    "    final_predictions = process_output(index_predictions)\n",
    "    accuracy = accuracy_score(y_test, final_predictions)\n",
    "    fbeta = fbeta_score(y_test, np.array(final_predictions) > 0.2, beta=2, average='samples')\n",
    "    return accuracy, fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.240551743356\n",
      "F-Beta: 0.240551743356\n"
     ]
    }
   ],
   "source": [
    "accuracy, fbeta = test_model(model, x_train, y_train)\n",
    "print(\"Accuracy: %s\" % accuracy)\n",
    "print(\"F-Beta: %s\" % fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.19775678  0.01599375  0.12535514  0.15254663  0.16253935  0.05017528\n",
      "  0.23774447]\n",
      "[ 0.13942088  0.01534347  0.09589794  0.18963067  0.27599072  0.02971552\n",
      "  0.22128241]\n",
      "[ 0.08286595  0.00503293  0.21117599  0.18083283  0.16052161  0.06070327\n",
      "  0.08705125]\n",
      "[ 0.07542466  0.01319412  0.09510279  0.11259545  0.12183733  0.13718136\n",
      "  0.10045666]\n",
      "[ 0.13808747  0.01606243  0.14586522  0.07773422  0.31515381  0.02709937\n",
      "  0.18898499]\n",
      "[ 0.19106981  0.01132473  0.21463723  0.0885046   0.19479358  0.14377536\n",
      "  0.10363218]\n",
      "[ 0.17313288  0.01040699  0.13746481  0.13556443  0.29119498  0.0289225\n",
      "  0.19583835]\n",
      "[ 0.07243594  0.00414225  0.0406423   0.74882782  0.05311485  0.0030676\n",
      "  0.0638709 ]\n",
      "[ 0.10955606  0.01256176  0.25321814  0.13511373  0.1204957   0.20275533\n",
      "  0.11717691]\n",
      "[ 0.14351358  0.00987771  0.13701455  0.34809428  0.19687808  0.0313373\n",
      "  0.08973194]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test, batch_size=128)\n",
    "index_predictions = []\n",
    "for row in predictions:\n",
    "    max_index = 0\n",
    "    max_value = row[0]\n",
    "    for index, value in enumerate(row):\n",
    "        if value > max_value:\n",
    "            max_index = index\n",
    "    index_predictions.append(max_index)\n",
    "final_predictions = process_output(index_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19775678,  0.01599375,  0.12535514, ...,  0.16253935,\n",
       "         0.05017528,  0.23774447],\n",
       "       [ 0.13942088,  0.01534347,  0.09589794, ...,  0.27599072,\n",
       "         0.02971552,  0.22128241],\n",
       "       [ 0.08286595,  0.00503293,  0.21117599, ...,  0.16052161,\n",
       "         0.06070327,  0.08705125],\n",
       "       ..., \n",
       "       [ 0.05237806,  0.01019659,  0.07280996, ...,  0.16076474,\n",
       "         0.05498865,  0.19568123],\n",
       "       [ 0.19393939,  0.01158739,  0.13539676, ...,  0.28887644,\n",
       "         0.05343383,  0.17328572],\n",
       "       [ 0.06644735,  0.00993373,  0.15354712, ...,  0.13058978,\n",
       "         0.02967988,  0.17463171]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2454722764\n",
      "F-Beta: 0.2454722764\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "fbeta = fbeta_score(y_test, np.array(final_predictions) > 0.2, beta=2, average='samples')\n",
    "print(\"Accuracy: %s\" % accuracy)\n",
    "print(\"F-Beta: %s\" % fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3589/3589 [==============================] - 29s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32979841217685124, 0.87151224452428211]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model(expanduser(\"~/emotion/model.hd5\"))\n",
    "model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "#print(\"Accuracy: %s\" % accuracy)\n",
    "#print(\"F-Beta: %s\" % fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3584/3589 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3272267019443108, 0.87258695953235743]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from import_data import process_images, process_output\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"fer2013.csv\")\n",
    "validation_set = data.loc[data['Usage'] == \"PublicTest\"]\n",
    "\n",
    "x_validate = process_images(validation_set[\"pixels\"])\n",
    "y_validate = process_output(validation_set[\"emotion\"])\n",
    "model.evaluate(x_validate, y_validate, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2583147 ,  0.04087767,  0.17710347, ...,  0.16430633,\n",
       "         0.08239405,  0.18856739],\n",
       "       [ 0.19169424,  0.04595682,  0.13225666, ...,  0.23552869,\n",
       "         0.06623318,  0.15513612],\n",
       "       [ 0.11494466,  0.02356886,  0.24118586, ...,  0.1780571 ,\n",
       "         0.11533236,  0.13640265],\n",
       "       ..., \n",
       "       [ 0.05745805,  0.01416327,  0.1017886 , ...,  0.14026503,\n",
       "         0.12957968,  0.25354853],\n",
       "       [ 0.24079879,  0.03113532,  0.11887378, ...,  0.22839639,\n",
       "         0.07385628,  0.1507092 ],\n",
       "       [ 0.12742852,  0.02527102,  0.22075914, ...,  0.20383018,\n",
       "         0.06784619,  0.24233304]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_test, batch_size=128)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"softmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_predictions = []\n",
    "for row in predictions:\n",
    "    max_index = 0\n",
    "    max_value = row[0]\n",
    "    for index, value in enumerate(row):\n",
    "        if value > max_value:\n",
    "            max_index = index\n",
    "    index_predictions.append(max_index)\n",
    "final_predictions = process_output(index_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0., -1.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0., -1.],\n",
       "       ..., \n",
       "       [-1.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0., -1., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions - y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2485.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference = np.sum((final_predictions * final_predictions) * (final_predictions - y_test))\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.84977432245807"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "sqrt(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30760657564781274"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(final_predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2713847868487044\n",
      "974 correct, 2615 incorrect\n"
     ]
    }
   ],
   "source": [
    "good = 0\n",
    "bad = 0\n",
    "for pred, test in zip(final_predictions, y_test):\n",
    "    if np.all(pred == test):\n",
    "        good = good + 1\n",
    "    else:\n",
    "        bad = bad + 1\n",
    "print(\"Accuracy: %s\" % (good / (good + bad)))\n",
    "print(\"%s correct, %s incorrect\" % (good, bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
